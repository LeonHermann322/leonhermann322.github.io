<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


	<title>Judge Alexa</title>

	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
	<meta name="referrer" content="no-referrer">

	<link rel="stylesheet" type="text/css" href="./assets/fonts.css">

	<link rel="stylesheet" type="text/css" href="./assets/bootstrap.css">
	<link rel="stylesheet" type="text/css" href="./assets/style.css">

</head>

<body>
	<nav class="container-fluid visible-md-block visible-lg-block" id="main-nav" style="top: 0px">
		<div class="container">
			<ul>
				<li><a class="scroll-link" data-target="intro" href="#intro">About</a></li>
				<li><a class="scroll-link" data-target="journey" href="#journey">Journey</a></li>
				<li><a class="scroll-link" data-target="faq" href="#faq">FAQ</a></li>
				<li><a class="scroll-link" data-target="setup" href="#setup">Setup</a></li>
				<li><a class="scroll-link" data-target="team" href="#team">Team</a></li>
			</ul>
		</div>
	</nav>

	<header class="container-fluid triangle" id="header">
		<div class="container">
			
			<div class="row">
				<div class="col-md-8 col-md-offset-2 text-center">
					<span class="title">Judge Alexa</span>
					<span class="subtitle">Wintersemester 21/22<br>Planung und Konstruktion von AI-basierten interaktiven Systemen mit einer "dunklen Seite der KI"</span>
					<a class="scroll-link btn icon-envelope" data-target="application" href="https://github.com/speydril/mycroft-core" style="font-weight: bold;color: #4c5ed6;background-color:#ffffff; width:25%; display:block; margin-left:37.5%; margin-right:auto; margin-top:5%">Download</a>
				</div>
			</div>
		</div>
		<div class="bg-overlay-gradient"></div>
		<div class="header-bg"></div>
	</header>
	<section class="container-fluid triangle" id="intro">
		<div class="container">
			<div class="row">
				<h1>What is Judge Alexa?</h1>
				<div class="block">
					<p>
						Judge Alexa is a free smart home assistant that is based on Mycroft Ai, the worlds's leading open source voice assistant.
						Our software runs on linux but can be used on micro processors as well. Since Judge Alexa is based on Mycroft it offers all its 
						functions including a vast variety of different skills to customize your user experience.
					</p>
					<p> 
						Additionally, Judge Alexa listens carefully to the users emotions to deliver more accurate and sensitive interaction. We
						used state of the art machine learning models to generate respones and analyze your current mood.
						Because of this exceptional technology we can guarantee you a stress free voice assistant!
					</p>
					<p>
						Have a look at Judge Alexa in action! 
					</p>
				</div>
			</div>
				<div class="videoWrapper">
					<iframe width="560" height="315" src="https://www.youtube.com/embed/KxAtGaJXZek" title="Judge Alexa Demo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
				</div>
			</div>
		</div>
	</section>
	<section class="container-fluid bg-overlay-gradient" id="journey">
		<div class="container">
			<div class="row">
				<h1>Journey</h1>
				<div class="block">
					<h2>Why Mycroft?</h2>	
					<p>
						Mycroft is open-source. This is a big advantage for us, since it allows more room for customization. 
						This perfectly allgins with our goals to listen and analyze the surroundings constantly.
						MyCroft does not require proprietary hardware, which allowed us to run it on any of our laptops and even Raspberry Pis. 
						Furthermore MyCroft already is a functional voice assistant, thus saving us a lot of time and effort. 
						These were our reasons for choosing MyCroft over other voice assistants like ALEXA or Google Assistant. 
						For more information about MyCroft have a look <a href="https://www.mycroft.ai">at their homepage</a> 
					</p>
					<h2>First Skill</h2>	
					<p>
						We wanted to evaluate the user and their behavior. Our first step was to recognize insults and decrease the social score of the user.
						Our idea was to create a skill and invoke it whenever the user utters an insult. With the MyCroft framework we were able to create such
						skill very easily. Now every time the user uttered an insult after saying "Hey Mycroft!" the users' score got decreased.
						The next step was to recognize insults in usual requests, without disrupting the normal functionality of MyCroft.
						We solved this by passing every utterance to our "Judge-Alexa-Skill" and checking if any insult could be found before
						continuing with the normal procedure. Should the score of the user fall below a certain threshold, our service would deny the request
						and tell the user to increase his score.
					</p>
					<h2>Constant Listening</h2>	
					<p>
						<a href="#"><img src="./assets/ww.png" class="logo img-responsive"></a>
						The most important feature to bring out the "dark" aspect for this seminar is the constant listening. We made MyCroft listen
						to every noise it picked up. The first challenge was to bypass the wakeword detection, which was required for MyCroft to
						process utterances. MyCroft records small audio chunks in a very short interval. These are added to a queue of a fixed length.
						Now for every interval MyCroft evaluates the queue and checks if a wakeword was found. At that time our solution was to
						only listen for a fixed amount of time and if no wakeword was found we would process the utterance regardless. The problem 
						with that implementation was that the normal functionality of MyCroft was compromised by a lot. As you can see in the diagram above
						MyCrofts speech recognition module normally waits for a wakeword and then records an utterance. The utterance gets converted to text 
						and then sent over to the skill handler via the message bus, which is used for communication between modules (messages are sent asynchronously).
						In the aforementioned implementation the speech recognition component only waits for the wakeword for our fixed amount of time and continues to
						send an utterance. These steps are repeated in a very short interval, since it is not waiting for speech. The issue that arises is our skill handler 
						which cannot process all of these utterances, because it discards the current utterance when a new one is received.
					</p>
					<p>
						We needed to find a way to only record at times when the user was speaking to reduce the number of emitted messages. For this we used the noise level of the surroundings. 
						MyCroft was still recording chunks, but not to process utterances but to adjust the current noise level. When the sound level of 
						a chunk exceeded a threshold depending on the current background noise level we started listening for the wakeword. Again, after our
						fixed amount of time, we proceeded to record an utterance regardless of a wakeword being said. 
					</p>
					<p>
						We didn't want MyCroft to respond to requests that did not include the wakeword, because these are requests that are not directed at it.
						To differentiate between these requests in the skill handler we emit an additional message over the bus, that tells the skill handler if 
						a wake word was found. With that we were able to even process dialog that is not directed at MyCroft while preserving the core functionality.
					</p>
					<h2>Tasks</h2>
					<p>
						When the score of the user would be too low, we give the user the option to increase his score by solving tasks. For one of our tasks
						we show the user a picture and ask them what they see. We designed this task having data labeling in mind and we wanted to show how our
						system would make use of the consumer to become even more intelligent. Sometimes we show the user images of already labeled data to verify
						that the user is really trying. If they answered the verifying question wrong, they would get a penalty by decreasing their score.
						This was one example of how we could exploit the user for machine learning purposes.
					</p>	
					<h2>Sentiment</h2>
					<p>
						<a href="#"><img src="./assets/log.png" class="logo img-responsive"></a>
						Another feature we wanted to implement was to analyze the current mood of the surroundings. We took a look at different way to do sentiment analysis in python.
						Ultimately we decided to use flair because of its simple usage and it being a trained NLP model, other than the other options we looked at like TextBlob or NLTK.
						With flair we are able to do a binary classification of utterances and label them as either positive or negative. 
						We then set an interval to check the most recent utterances and then try to look at coherent dialog rather than atomic utterances to determine the overall sentiment.
						You can see an exemplary sentence as it would be classified in the screenshot above.
						Depending on the mood we would increase or decrease the score of the user a bit.
					</p>	
					<h2>GPT3</h2>	
					<p>
						GPT3 is something that we came across when we thought of ways to improve Judge Alexa. With GPT3 we found a way to make Judge Alexa even smarter.
						Through the OpenAI API we are able to produce creative responses in realtime. We added a feature where Judge Alexa would listen to the surrounding and then
						say something if it would get too loud. The phrase would depend on the surrounding noise level. Now that we had GPT3 included we were able to produce 
						grammatically correct sentences that even made sense. We wanted to make use of this technology to take Jude Alexa to the next level.
					</p>
					<h2>Voice Cloning</h2>
					<p>
						To make Judge Alexa more convincing to the user, we wanted to integrate Voice Cloning into our system. We added a voice task that asks the user to
						repeat a phrase generated by GPT-3 and recorded the response. We could now use those sound snippets to clone the users voice and vocalize sentences of our choosing.
						However, we have to mention that the voice cloning model we used was trained on british english, so it doesn't work as well on accented english of non-native speakers.
						As neural networks work best with GPU-support we first tried to use an external GPU with a Linux laptop, but we soon discovered that using
						an external GPU is not easy. Because problems with the Thunderbolt-3-connection were blocking us from using the external GPU, we resorted to
						a built-in GPU instead. For that we had to sacrifice running Judge Alexa on a Raspberry Pi, but we could successfully clone the users voice.
						In theory Judge Alexa can still be run on micro processors with a powerful built-in GPU like the Nvidia Jetson series, but we didn't have the
						chance to test it.
					</p>
				</div>
			</div>
			
			</div>
		</div>
	</section>
	<section class="container-fluid bg-grey" id="faq">
		<div class="container">
			<div class="row">
				<div class="col-md-12">
					<h1>Frequently asked questions</h1>
				</div>
			</div>
			<div class="row">
				<div class="col-md-5">
					<div class="faq-question">
						<h2 class="text-colored">What's so special about Judge Alexa?</h2>
						<div class="block">
							<p>
								Most voice assistants are either expensive or have limited functionality. With Judge Alexa we offer
								both. A full functional voice assistant for free!
							</p> 
						</div>
					</div>
					<div class="faq-question">
						<h2 class="text-colored">Is my data safe?</h2>
						<div class="block">
							<p>
								We can assure you that we only use your data for improving your user experience and there is 
								no intention of sending your data to third party organisations.
							</p>
						</div>
					</div>
					<div class="faq-question">
						<h2 class="text-colored">How to setup Judge Alexa</h2>
						<div class="block">
							<p>
								Setting up Judge Alexa is simple. Just click on the download section and read the README.md for the setup.
							</p>
						</div>
					</div>
				</div>
				<div class="col-md-5 col-md-offset-1">
					<div class="faq-question">
						<h2 class="text-colored">Are there any requirements?</h2>
						<div class="block">
							<p>
								You only need a Linux system that satisfy the Mycroft requirements. For more information on this please visit <a href="https://mycroft-ai.gitbook.io/docs/using-mycroft-ai/get-mycroft/linux">Linux Prerequisites</a>.
							</p>
						</div>
					</div>
					<div class="faq-question">
						<h2 class="text-colored">So Mycroft is free and fully functional. What's the catch?</h2>
						<div class="block">
							<p>
								This is the good thing! There is no catch. If you want to be 100% sure about it just read our <a href="termsOfService.html">Terms of Service</a>.
							</p>
						</div>
					</div>
				</div>
			</div>
		</div>
	</section>
	<section class="container-fluid bg-overlay-gradient" id="setup">
		<div class="container">
			<h1>Setup</h1>
			<h2>Requirements - What you need</h2>
			<p>To setup Judge Alexa we recommend the following things:</p>
			<ul>
				<li>Ubuntu 20.04</li>
				<li>Python 3.8</li>
				<li>NVIDIA GPU</li>
				<li>Make sure that you can run <a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning"> Real Time Voice Cloning ToolBox</a>. 
				Just follow the instructions there and install the requirements globally. 
				</li>
			  </ul>
			  <h2>Instructions</h2>
			  <p>Next up follow these steps</p>
			<ol>
				<li>First go to <a href="https://github.com/speydril/mycroft-core">https://github.com/speydril/mycroft-core</a> and clone the repository</li>
				<li>Run the dev_setup.sh and make sure you chose local options like running unstable branches and building MIMIC locally. There might be a error cause by flair but
					that shouldn't cause any problems later on.
				</li>
				<li>After finishing the setup go to the directory <code>/opt/mycroft/skills</code> on your PC and clone <a href="https://github.com/LeonHermann322/judgealexa-skill">JudgeAlexaSkill</a> and
					 <a href="https://github.com/LeonHermann322/taskbot-skill">TaskBot Skill</a> into that directory</li>
				<li>Extract the <a href="https://drive.google.com/file/d/1xMV9cUCsLFFKEI2vyhmyCSC1jpX3B6Ox/view?usp=sharing">animal_dataset.zip</a> into the task bot folder</li>
				<li>Go to <a href="https://openai.com/api/">openAI</a> and make an account to get an API KEY</li>
				<li>create a .env file in the taskbot-skill folder and paste the API key as the <code>OPENAI_API_KEY</code> variable </li>
				<li>Add the folder /tmp/judge_evidence</li>
				<li>Now run <code>./start-mycroft.sh debug</code> in the mycroft-core folder and follow the instructions there. (Note that when you run the script for the first time 
					you have to register your device which might take a while, so just wait a little
				</li>
			</ol>
			<h2>Things to know</h2>
			<p>If you have successfully setup JudgeAlexa then here are some last things we want you to know</p>
			<ul>
				<li>in /tmp/judge_evidence you can find the files that JudgeAlexa recorded</li>
				<li>if you dont want to solve tasks just adjust your score in the scoreFile.txt in the mycroft-core folder ;)</li>
				<li>you can find every utterance that got recognized in the <code>mycroft-core/utterances.txt</code></li>
				<li>in the <code>mycroft-core/sentiments.txt</code> you can find the corresponding sentiment classification</li>
			  </ul>
		</div>
	</section>
	<section class="container-fluid bg-grey" id="team">
		<div class="container">
			<div class="row">
				<div class="col-md-12 top50">
					<h1 class="text-center">Team</h1>
				</div>
			</div>
			<div class="row">
				<div class="col-md-12">
					<div class="team-member col-md-4">
						<span class="member-title">Leon Hermann</span>
					</div>
					<div class="team-member col-md-4">
						<span class="member-title">Florian MÃ¼ller</span>
					</div>
					<div class="team-member col-md-4">
						<span class="member-title">An Nguyen</span>
					</div>
				</div>
			</div>
		</div>
	</section>

	<footer class="container-fluid" id="footer">
		<div class="container">
			<div class="row">
				<div class="col-md-4">
					<a href="#"><img src="./assets/logo.png" class="logo img-responsive"></a>
				</div>
				<div class="col-md-4">
					<span class="column-title">Judge Alexa</span>
					<ul>
						<li><a href="https://github.com/speydril/mycroft-core" target="_blank">Github</a></li>
						<li><a href="termsOfService.html" target="_blank">Terms of Service</a></li>
					</ul>
				</div>
			</div>
		</div>
	</footer>

	<script type="text/javascript" src="./assets/jquery.min.js"></script>
	<script type="text/javascript" src="./assets/app.js"></script>


</body></html>
